{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HimaliShewale/Python/blob/main/Project%20of%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "J-XHqZfgSVZV",
        "outputId": "a365baa4-da11-4556-c020-b8b76bcc199d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the restaurants analytics tool!\n",
            "   Review_ID  Rating Year_Month     Reviewer_Location  \\\n",
            "0  670772142       4     2019-4             Australia   \n",
            "1  670682799       4     2019-5           Philippines   \n",
            "2  670623270       4     2019-4  United Arab Emirates   \n",
            "3  670607911       4     2019-4             Australia   \n",
            "4  670607296       4     2019-4        United Kingdom   \n",
            "\n",
            "                                         Review_Text               Branch  \n",
            "0  If you've ever been to Disneyland anywhere you...  Disneyland_HongKong  \n",
            "1  Its been a while since d last time we visit HK...  Disneyland_HongKong  \n",
            "2  Thanks God it wasn   t too hot or too humid wh...  Disneyland_HongKong  \n",
            "3  HK Disneyland is a great compact park. Unfortu...  Disneyland_HongKong  \n",
            "4  the location is not in the city, took around 1...  Disneyland_HongKong  \n",
            "sent\n",
            "  Disneyland_California 0.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-19e83ad2bad7>\u001b[0m in \u001b[0;36m<cell line: 212>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-19e83ad2bad7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m               \u001b[0mdata_visualization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m           \u001b[0;32melif\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sentimentanalysis'\u001b[0m\u001b[0;34m:\u001b[0m                           \u001b[0;31m#go to reception function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m               \u001b[0msentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m           \u001b[0;32melif\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'machinelearning'\u001b[0m\u001b[0;34m:\u001b[0m                              \u001b[0;31m#go to poster function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m               \u001b[0mmachine_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-19e83ad2bad7>\u001b[0m in \u001b[0;36msentiment_analysis\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The analysis is not supported, please try again\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m           \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Would you like to run another sentiment analysis (yes/no)?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m           \u001b[0manalysis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "from IPython.core.display import JSON\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus.reader import reviews\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import sys, requests, json, urllib, io, csv, sklearn.model_selection\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io\n",
        "import wordcloud, sklearn\n",
        "import nltk, requests, textblob\n",
        "from textblob import TextBlob\n",
        "import warnings\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download(\"punkt\")\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import requests\n",
        "import urllib.request\n",
        "import IPython\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io\n",
        "import wordcloud\n",
        "import nltk, requests, textblob\n",
        "from textblob import TextBlob\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "def piecharts(data):\n",
        " rating = data[\"Rating\"].value_counts()\n",
        " plt.pie(x = rating, autopct='%1.1f%%', textprops=dict(color='white'))\n",
        " plt.legend(labels = rating.index)\n",
        " plt.show()\n",
        " branch = data[\"Branch\"].value_counts()\n",
        " plt.pie(x = branch, autopct='%1.1f%%', textprops=dict(color='white'))\n",
        " plt.legend(labels = branch.index)\n",
        " plt.show()\n",
        "\n",
        "def wordclouds(data):\n",
        "   for line in data[\"Review_Text\"]:\n",
        "       text= line\n",
        "   cloud = wordcloud.WordCloud()\n",
        "   cloud.generate(text)\n",
        "\n",
        "   plt.imshow(cloud, interpolation = \"bilinear\")\n",
        "   plt.axis(\"off\")\n",
        "   plt.show()\n",
        "\n",
        "\n",
        "def data_visualization(data):\n",
        "  print(\"data\")\n",
        "  data_analysis ='yes'\n",
        "  while data_analysis == 'yes':\n",
        "          user_input = TextBlob(input('What type of Data you want to see(Pie Charts/Word Cloud)?')).lower().strip()\n",
        "          user_input= user_input.correct()\n",
        "          if user_input == 'piecharts':                            #go to background function\n",
        "              piecharts(data)\n",
        "          elif user_input == 'wordcloud':                           #go to reception function\n",
        "              wordclouds(data)\n",
        "\n",
        "          else:\n",
        "            print(\"The analysis is not supported, please try again\")\n",
        "\n",
        "          data_analysis = TextBlob(input('Would you like to run another data visualization (yes/no)?')).lower().strip()\n",
        "          data_analysis=data_analysis.correct()\n",
        "\n",
        "def polarity(data):\n",
        "    text = \"\"\n",
        "    company = input(\"What company would you like to analyze?\").strip().lower()\n",
        "    if company not in companies:\n",
        "      print(\"Please Enter Valid Twitter handle\")\n",
        "    else:\n",
        "      for line in data:\n",
        "        if line['Company'].lower() == company:\n",
        "         new_text = line[\"Text\"]\n",
        "         text = text+new_text\n",
        "      blob= textblob.TextBlob(text)\n",
        "      print(\" \",company , blob.polarity)\n",
        "\n",
        "def subjectivity(data):\n",
        "    branches = [\"Disneyland_HongKong\",\"Disneyland_Paris\",\"Disneyland_California\"]\n",
        "    text = \"\"\n",
        "    branch = input(\"Which Branch would you like to analyze?\")\n",
        "    if branch not in branches:\n",
        "      print(\"Please Enter Valid Branch\")\n",
        "    else:\n",
        "      for line in data[\"Branch\"]:\n",
        "        if line[5] == branch :\n",
        "          print(line[5])\n",
        "          new_text = line[4]\n",
        "          text = text+new_text\n",
        "      blob= textblob.TextBlob(text)\n",
        "      print(\" \",branch , blob.subjectivity)\n",
        "\n",
        "def sentiment_analysis(data):\n",
        "  print(\"sent\")\n",
        "  sent_analysis ='yes'\n",
        "  while sent_analysis == 'yes':\n",
        "          user_input = TextBlob(input('What type of Data you want to see(Polarity/ Subjectivity)?')).lower().strip()\n",
        "          user_input= user_input.correct()\n",
        "          if user_input == 'polarity':                            #go to background function\n",
        "              polarity(data)\n",
        "          elif user_input == 'subjectivity':                           #go to reception function\n",
        "              subjectivity(data)\n",
        "\n",
        "          else:\n",
        "            print(\"The analysis is not supported, please try again\")\n",
        "\n",
        "          sent_analysis = TextBlob(input('Would you like to run another sentiment analysis (yes/no)?')).lower().strip()\n",
        "          sent_analysis=sent_analysis.correct()\n",
        "\n",
        "def machine_learning(data):\n",
        "\n",
        "  vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(stop_words=stopwords.words(\"english\"), max_features=1000)\n",
        "  X = vectorizer.fit_transform(data[\"Review_Text\"])\n",
        "  Y = (data[\"Rating\"])\n",
        "\n",
        "\n",
        "\n",
        "  X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.7, random_state=25)\n",
        "\n",
        "\n",
        "# Train and evaluate decision tree classifier\n",
        "  dt_clf = sklearn.tree.DecisionTreeClassifier()\n",
        "  dt_clf = dt_clf.fit(X_train, Y_train)\n",
        "  dt_predictions = dt_clf.predict(X_test)\n",
        "  dt_accuracy = sklearn.metrics.accuracy_score(Y_test, dt_predictions)\n",
        "  print(\"DT accuracy:\", dt_accuracy)\n",
        "\n",
        "# Train and evaluate kNN classifier\n",
        "  knn_clf = sklearn.neighbors.KNeighborsClassifier(5)\n",
        "  knn_clf = knn_clf.fit(X_train, Y_train)\n",
        "  knn_predictions = knn_clf.predict(X_test)\n",
        "  knn_accuracy = sklearn.metrics.accuracy_score(Y_test, knn_predictions)\n",
        "  print(\"KNN accuracy:\", knn_accuracy)\n",
        "\n",
        "# Train and evaluate neural network classifier\n",
        "  nn_clf = sklearn.neural_network.MLPClassifier()\n",
        "  nn_clf = nn_clf.fit(X_train, Y_train)\n",
        "  nn_predictions = nn_clf.predict(X_test)\n",
        "  nn_accuracy = sklearn.metrics.accuracy_score(Y_test, nn_predictions)\n",
        "  print(\"NN accuracy:\", nn_accuracy)\n",
        "\n",
        "  if nn_accuracy >= dt_accuracy and nn_accuracy >= knn_accuracy:\n",
        "    print(\"Neural network is the most accurate model.\")\n",
        "    print(sklearn.metrics.classification_report(Y_test, nn_predictions,target_names = [\"No Funding\", \"Funding\"]))\n",
        "    cm = sklearn.metrics.confusion_matrix(Y_test, nn_predictions)\n",
        "    print(cm)\n",
        "    disp = sklearn.metrics.ConfusionMatrixDisplay(cm)\n",
        "    disp.plot()\n",
        "    plt.show()\n",
        "    joblib.dump(nn_clf, \"neural_network.joblib\")\n",
        "    google.colab.files.download(f\"neural_network.joblib\")\n",
        "  elif dt_accuracy >= nn_accuracy and dt_accuracy >= knn_accuracy:\n",
        "    print(\"Decision tree is the most accurate model.\")\n",
        "    print(sklearn.metrics.classification_report(Y_test, dt_predictions,target_names = [\"No Funding\", \"Funding\"]))\n",
        "    cm = sklearn.metrics.confusion_matrix(Y_test, dt_predictions)\n",
        "    print(cm)\n",
        "    disp = sklearn.metrics.ConfusionMatrixDisplay(cm)\n",
        "    disp.plot()\n",
        "    plt.show()\n",
        "    joblib.dump(dt_clf, \"decision_tree.joblib\")\n",
        "    google.colab.files.download(f\"decision_tree.joblibb\")\n",
        "  else:\n",
        "    print(\"KNN is the most accurate model.\")\n",
        "    print(sklearn.metrics.classification_report(Y_test, knn_predictions, target_names = [\"No Funding\", \"Funding\"]))\n",
        "    cm = sklearn.metrics.confusion_matrix(Y_test, knn_predictions)\n",
        "    print(cm)\n",
        "    disp = sklearn.metrics.ConfusionMatrixDisplay(cm)\n",
        "    disp.plot()\n",
        "    plt.show()\n",
        "    joblib.dump(knn_clf, \"k_nearest_neighbors.joblib\")\n",
        "    google.colab.files.download(f\"k_nearest_neighbors.joblib\")\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    print(\"Welcome to the restaurants analytics tool!\")\n",
        "    analysis = 'yes'\n",
        "    #movie_input = (input(\"What movie would you like to analyze?\")).lower().strip()\n",
        "\n",
        "    data = pd.read_csv(\"DisneylandReviews.csv\", encoding='latin-1')\n",
        "    data.drop_duplicates('Review_ID', inplace=True, keep='first')\n",
        "    print(data.head())\n",
        "    while analysis == 'yes':\n",
        "          user_input = TextBlob(input('What would you like to see (Visualize Data/Sentiment Analysis/Machine learning(Models))?')).lower().strip()\n",
        "          user_input= user_input.correct()                          #spelling correction using correct() function\n",
        "\n",
        "          if user_input == 'visualizedata':                            #go to background function\n",
        "              data_visualization(data)\n",
        "          elif user_input == 'sentimentanalysis':                           #go to reception function\n",
        "              sentiment_analysis(data)\n",
        "          elif user_input == 'machinelearning':                              #go to poster function\n",
        "              machine_learning(data)\n",
        "\n",
        "          else:\n",
        "            print(\"The analysis is not supported, please try again\")\n",
        "\n",
        "          analysis = TextBlob(input('Would you like to run another analysis (yes/no)?')).lower().strip()\n",
        "          analysis=analysis.correct()                               #spelling correction using correct() function\n",
        "\n",
        "    else:\n",
        "      print(\"Connection Error please try again\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sys.exit(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "vB3ly5ikGlOL"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO81S2G94c3Z0y3UP3z3J3j",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}